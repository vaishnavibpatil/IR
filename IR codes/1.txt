import nltk 
from nltk.corpus import stopwords 
from nltk.tokenize import word_tokenize 
from nltk.stem import PorterStemmer,WordNetLemmatizer

nltk.download('stopwords') 
nltk.download('punkt_tab') 
nltk.download('wordnet')

text_document = "Text preprocessing is an essential step in NLP. It includes task like stop word removal and stmming."

words = word_tokenize(text_document) 
print(words)

stop_words = set(stopwords.words('english')) 
filtered_words = [word for word in words if word.lower() not in stop_words] 
filtered_words 

stemmer = PorterStemmer() 

stemmed_words = [stemmer.stem(word) for word in filtered_words] 
stemmed_words 

lemmatizer = WordNetLemmatizer() 

lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]
print(lemmatized_words)